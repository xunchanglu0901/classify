{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import precision_recall_curve  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ä¸‹é¢è¿™ä¸ªæ¡†ä¸éœ€è¦æ”¹åŠ¨ä¹Ÿä¸éœ€è¦äº†è§£ï¼Œæ˜¯å»ºç«‹äº†\"è¿›åº¦æ¡\"ï¼Œä¸ºäº†æ˜¾ç¤ºåç»­\"FORå¾ªç¯\"çš„è¿›åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "class ProgressBar():\n",
    "\n",
    "    def __init__(self, max_steps):\n",
    "        self.max_steps = max_steps\n",
    "        self.current_step = 0\n",
    "        self.progress_width = 50\n",
    "\n",
    "    def update(self, step=None):\n",
    "        self.current_step = step\n",
    "\n",
    "        num_pass = int(self.current_step * self.progress_width / self.max_steps) + 1\n",
    "        num_rest = self.progress_width - num_pass \n",
    "        percent = (self.current_step+1) * 100.0 / self.max_steps \n",
    "        progress_bar = '[' + 'â– ' * (num_pass-1) + 'â–¶' + '-' * num_rest + ']'\n",
    "        progress_bar += '%.2f' % percent + '%' \n",
    "        if self.current_step < self.max_steps - 1:\n",
    "            progress_bar += '\\r' \n",
    "        else:\n",
    "            progress_bar += '\\n' \n",
    "        sys.stdout.write(progress_bar) \n",
    "        sys.stdout.flush()\n",
    "        if self.current_step >= self.max_steps:\n",
    "            self.current_step = 0\n",
    "            print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å¯¼å…¥æ•°æ®\n",
    "#### æ ¹æ®è‡ªå·±çš„è·¯å¾„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"C:\\\\Users\\\\iii\\\\Desktop\\\\data-y.xls\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ç¬¬ä¸€è¡Œæ˜¯è¯»å–å‡ºæ¥\n",
    "#### ç¬¬äºŒè¡Œæ˜¯æ’è¡¥â€œçº¿æ€§æ’è¡¥â€ç¼ºå¤±å€¼ ğŸ‘‰ å­˜åœ¨ç¼ºå¤±å€¼æ˜¯æ— æ³•å»ºæ¨¡\n",
    "#### ç¬¬ä¸‰è¡Œæ˜¯è¾“å‡ºâ€œåˆ—åâ€ï¼Œå³å˜é‡åç§°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['æ€§åˆ«', 'ç”·', 'å¹´é¾„', 'å¹´é¾„æ®µ', 'æ”¿æ²»é¢è²Œ', 'å…šå‘˜', 'æ•™è‚²å¹´é™', 'æ•™è‚²ç¨‹åº¦', 'èŒä¸šä¹ç±»', 'å®¶åº­å¹³å‡å¹´æ”¶å…¥',\n",
      "       'åœ°åŒº', 'åˆ†åŒº', 'æ–‡åŒ–', 'åˆ¶åº¦', 'å¼ºç›‘ç£åª’ä½“ä½¿ç”¨', 'å¼±ç›‘ç£åª’ä½“ä½¿ç”¨', 'å¼ºç›‘ç£åª’ä½“ä¿¡ä»»', 'å¼±ç›‘ç£åª’ä½“ä¿¡ä»»',\n",
      "       'æ„è¯†å½¢æ€', 'å·¦', 'å³', 'Y1', 'Y2', 'Y3', 'Y4', 'Ya', 'Yb', 'Yc', 'Yd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(input_data)\n",
    "data = data.interpolate(method='linear')\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ä¸‹é¢æ˜¯æ„å»ºæ–°å˜é‡ï¼šâ‘ â‘¡ä¹˜æ³•æ„å»ºæ–°å˜é‡ JH1å’ŒJH2  â‘¢ åŠ æ³•æ„å»ºæ–°å˜é‡ğŸ‘‰äºŒåˆ†ç±»çš„Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"JH1\"] = data['æ„è¯†å½¢æ€'] * data['å¼ºç›‘ç£åª’ä½“ä½¿ç”¨']\n",
    "data[\"JH2\"] = data['æ„è¯†å½¢æ€'] * data['å¼ºç›‘ç£åª’ä½“ä¿¡ä»»']\n",
    "data['Y'] = data['Y1'] + data['Y2'] + data['Y3'] + data['Y4']\n",
    "# print(data[\"JH2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### independ_feature ğŸ‘‰ è§£é‡Šå˜é‡ Xå’ŒD\n",
    "#### depend_feature ğŸ‘‰ è¢«è§£é‡Šå˜é‡ Y\n",
    "#### ä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€è¦ğŸ‘‰åœ¨é‡Œé¢æ·»åŠ ã€æ›´æ¢ã€åˆ é™¤å˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "independ_feature = [ 'ç”·',  'å¹´é¾„æ®µ', 'æ”¿æ²»é¢è²Œ',  'æ•™è‚²ç¨‹åº¦', 'èŒä¸šä¹ç±»', 'å®¶åº­å¹³å‡å¹´æ”¶å…¥',\n",
    "       'åœ°åŒº', 'åˆ†åŒº', 'æ–‡åŒ–', 'åˆ¶åº¦', 'å¼ºç›‘ç£åª’ä½“ä½¿ç”¨',  'å¼ºç›‘ç£åª’ä½“ä¿¡ä»»', 'æ„è¯†å½¢æ€', 'JH1','JH2']\n",
    "\n",
    "depend_feature = ['Yd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ä¸Šé¢çš„æ­¥éª¤é€‰å®šäº†æ‰€ç”¨å˜é‡ï¼Œä¸‹é¢ä¸¤è¡Œæ˜¯æŠŠdataæ ¹æ®è§£é‡Šå˜é‡ã€è¢«è§£é‡Šå˜é‡åˆ†æˆä¸¤ä¸ªéƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[independ_feature]\n",
    "y = data[depend_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å„ä¸ªæ¨¡å‹ï¼Œè¯·ä»”ç»†çœ‹æ³¨é‡Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å†³ç­–å›å½’\n",
    "# clf0 = DecisionTreeRegressor(criterion='mse',max_depth=4)\n",
    "\n",
    "# å†³ç­–åˆ†ç±» ğŸ‘‰ â‘ entropyæ˜¯ä¿¡æ¯ç†µ;å¯ä»¥æ¢æˆginiâ‘¡å¶å­èŠ‚ç‚¹æœ€å°‘çš„æ ·æœ¬æ•°=350,è¯•å€¼åå‘ç°è¿™ä¸ªå¤§å°ç²¾åº¦å¥½\n",
    "clf_tree = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=350)\n",
    "\n",
    "\n",
    "# éšæœºæ£®æ—åˆ†ç±»ğŸ‘‰â‘ åŒä¸Šâ‘¡åŒä¸Šâ‘¢ç›¸å½“äºä¸€ä¸ªéšæœºæ£®æ—æœ‰\"300\"ä¸ªæ ‘\n",
    "clf_rf = RandomForestClassifier(criterion='entropy', min_samples_leaf=350, n_estimators=300)\n",
    "\n",
    "\n",
    "# æ”¯æŒå‘é‡æœºåˆ†ç±»ğŸ‘‰â‘ æ ¸å‡½æ•°ï¼šlinear çº¿æ€§; rbf å¾„å‘åŸºæ ¸å‡½æ•°\n",
    "clf_svc = svm.SVC(kernel='linear')\n",
    "\n",
    "\n",
    "# ç¥ç»ç½‘ç»œğŸ‘‰åŸºäºå¤šå±‚æ„ŸçŸ¥æœºâ‘ solveræœ‰lbfgs,sgd,adamç”¨æ¥ä¼˜åŒ–æƒé‡,è®ºæ–‡å¯ç›´æ¥ä½¿ç”¨è‹±æ–‡åå­—,æ— éœ€è¯¦ç»†è®ºè¿° \n",
    "#                          â‘¡alphaæ˜¯æ­£åˆ™åŒ–å‚æ•°(é˜²æ­¢è¿‡æ‹Ÿåˆ),1e-5å³0.00001\n",
    "#                          â‘¢hidden_   =(10,15,5)çš„æ„æ€æ˜¯,æœ‰â€œ3â€ä¸ªéšè—å±‚ï¼Œæ¯å±‚ç¥ç»å…ƒâ€œ10ï¼Œ15ï¼Œ5â€ä¸ªğŸ‘‰çœ‹ç€è°ƒå§,æˆ‘è®ºæ–‡ä¹Ÿçè¯•çš„...\n",
    "#                          â‘£max_iter è¿­ä»£è®¡ç®—æ¬¡æ•°ï¼Œä¸€èˆ¬å‡ ç™¾å°±å¤Ÿäº†ï¼Œå¤ªå¤šäº†ä¹Ÿä¸ä¸€å®šé«˜ã€‚\n",
    "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(10,15, 5),random_state=1, max_iter=300)\n",
    "\n",
    "\n",
    "# KNNğŸ‘‰â‘ n+neighborsæ¯â€œ450â€ä¸ªç®—ä¸€ä¸ªâ€œé‚»è¿‘â€èŒƒå›´ï¼Œå¯è°ƒï¼Œæˆ‘è¯•äº†è¯•ï¼Œ450å·¦å³è¿˜ç®—å¯ä»¥ï¼ŒåæœŸæ—¶é—´å……è£•å†è°ƒ\n",
    "#       â‘¡weights='distance'å³ æ•°æ®å·®è·è¶Šå¤§ï¼Œè¶Šé¥è¿œã€‚\n",
    "#       â‘¢leaf_size=30 é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œé»˜è®¤30 å¯åŠ å¤§\n",
    "#       â‘£ p=2, metric='minkowski'å³é—µå¯å¤«æ–¯åŸºè·ç¦»ï¼Œå¸¸ç”¨ï¼Œä¸å»ºè®®æ”¹\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=450, weights='distance',\n",
    "                           leaf_size=66, p=2, metric='minkowski')\n",
    "                          \n",
    "# çº¿æ€§åˆ¤åˆ«\n",
    "# solver:ğŸ‘‰svdï¼šå¥‡å¼‚å€¼åˆ†è§£æ±‚è§£ï¼Œæ— éœ€è®¡ç®—åæ–¹å·®çŸ©é˜µï¼Œé€‚ç”¨äºç‰¹å¾æ•°é‡å¤§æƒ…å½¢ï¼›ã€å…¶ä»–ã€‘lsqrï¼šæœ€å°å¹³æ–¹QRåˆ†è§£ï¼›eigenï¼šç‰¹å¾å€¼åˆ†è§£ï¼›\n",
    "clf_lda = LinearDiscriminantAnalysis(solver='svd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¸ºäº†æ–¹ä¾¿å¤šæ¬¡è¯•éªŒï¼š\n",
    "#### å»ºç«‹forå¾ªç¯ï¼šæ¯æ¬¡å¾ªç¯éšå³åˆ‡å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼›å¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œå›å½’ï¼Œè®¡ç®—æ¯ä¸€æ¬¡è¯¯å·®å¹¶è¾“å‡ºexcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–¶]100.00%\n"
     ]
    }
   ],
   "source": [
    "# è¿™é‡Œå»ºç«‹è¯¯å·®åˆ—è¡¨ğŸ‘‰æ–¹ä¾¿åé¢è¾“å‡ºåˆ°excel\n",
    "re_list = list()\n",
    "accuracy_list = list()\n",
    "f1_list = list()\n",
    "precision_list = list()\n",
    "recall_list = list()\n",
    "roc_auc_list = list()\n",
    "\n",
    "# å¾ªç¯å¤šæ¬¡è¯•éªŒ\n",
    "test_count = 100  # ğŸ‘ˆ ä¿®æ”¹æ•°å­—å¾—åˆ°å¤šæ¬¡å®éªŒç»“æœ\n",
    "progress_bar = ProgressBar(test_count)  # è¿›åº¦æ¡ğŸ‘‰å±•ç¤ºå¾ªç¯ã€æ€»ã€‘è¿›åº¦ï¼Œä¸éœ€è¦äº†è§£\n",
    "\n",
    "\n",
    "for test_num in range(0,test_count):\n",
    "    progress_bar.update(test_num)  # è¿›åº¦æ¡ã€æ€»ã€‘è¿›åº¦ï¼Œä¸éœ€è¦äº†è§£ \n",
    "    \n",
    "    # åˆ’åˆ†ğŸ‘‰0.2æ˜¯æµ‹è¯•é›†å æ¯”ï¼Œå¯è°ƒ\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)  # ğŸ‘ˆ å æ¯”0.2 å¯è°ƒ\n",
    "    # è°ƒæ•´æ ¼å¼ï¼Œä¾¿äºè®¡ç®—ï¼Œç”±åŸå…ˆçš„æ•°æ®æ¡†â†’æ•°åˆ—\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "    #å„ä¸ªæ¨¡å‹ï¼šè¿›è¡Œæ‹Ÿåˆ\n",
    "    clf_tree.fit(x_train,y_train)\n",
    "    clf_rf.fit(x_train,y_train)\n",
    "    clf_svc.fit(x_train,y_train)\n",
    "    clf_mlp.fit(x_train,y_train)\n",
    "    clf_knn.fit(x_train,y_train) \n",
    "    clf_lda.fit(x_train,y_train)\n",
    "    \n",
    "    #å„ä¸ªæ¨¡å‹ï¼šé¢„æµ‹é›†ã®é¢„æµ‹ç»“æœ\n",
    "    predict_tree = clf_tree.predict(x_test)  #å„ä¸ªæ¨¡å‹ï¼šé¢„æµ‹ç»“æœ\n",
    "    predict_rf = clf_rf.predict(x_test)  #å„ä¸ªæ¨¡å‹ï¼šé¢„æµ‹ç»“æœ        \n",
    "    predict_svc = clf_svc.predict(x_test)  #å„ä¸ªæ¨¡å‹ï¼šé¢„æµ‹ç»“æœ\n",
    "    predict_mlp = clf_mlp.predict(x_test)  #å„ä¸ªæ¨¡å‹ï¼šé¢„æµ‹ç»“æœ\n",
    "    predict_knn = clf_knn.predict(x_test)  #å„ä¸ªæ¨¡å‹ï¼šé¢„æµ‹ç»“æœ\n",
    "    predict_lda = clf_lda.predict(x_test)  #å„ä¸ªæ¨¡å‹ï¼šé¢„æµ‹ç»“æœ\n",
    "    \n",
    "    # è¯¯å·®ã® RE ç›¸å¯¹è¯¯å·®ğŸ‘‰â‘ ï¼ˆï¼‰æ˜¯é¢„æµ‹å’ŒçœŸå®çš„å·®â‘¡å·®ä¸æ˜¯0çš„æ€»æ•°â‘¢é™¤ä»¥æµ‹è¯•é›†æ ·æœ¬é‡â†’RE\n",
    "    re_tree = ((predict_tree - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test)\n",
    "    re_rf = ((predict_rf - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test)\n",
    "    re_svc = ((predict_svc - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test) \n",
    "    re_mlp = ((predict_mlp - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test)  \n",
    "    re_knn = ((predict_knn - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test)  \n",
    "    re_lda = ((predict_lda - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test)  \n",
    "    \"\"\"\n",
    "    print(\"å†³ç­–æ ‘è¯¯å·®:%.3f\" % re_tree, \"éšæœºæ£®æ—è¯¯å·®:%.3f\" % re_rf, \"æ”¯æŒå‘é‡æœºè¯¯å·®:%.3f\" % re_svc,\n",
    "          \"ç¥ç»ç½‘ç»œè¯¯å·®:%.3f\" % re_mlp, \"KNNè¯¯å·®:%.3f\" % re_knn, \"çº¿æ€§åˆ¤åˆ«è¯¯å·®:%.3f\" % re_lda, sep=\"\\n\")\n",
    "    \"\"\"\n",
    "    # å‡†ç¡®åº¦ accuracy_score \n",
    "    accuracy_tree = accuracy_score(y_test, predict_tree)\n",
    "    accuracy_rf = accuracy_score(y_test, predict_rf)\n",
    "    accuracy_svc = accuracy_score(y_test, predict_svc)\n",
    "    accuracy_mlp = accuracy_score(y_test, predict_mlp)\n",
    "    accuracy_knn = accuracy_score(y_test, predict_knn)\n",
    "    accuracy_lda = accuracy_score(y_test, predict_lda)\n",
    "    # f1_score\n",
    "    f1_tree = f1_score(y_test, predict_tree)\n",
    "    f1_rf = f1_score(y_test, predict_rf)\n",
    "    f1_svc = f1_score(y_test, predict_svc)\n",
    "    f1_mlp = f1_score(y_test, predict_mlp)\n",
    "    f1_knn = f1_score(y_test, predict_knn)\n",
    "    f1_lda = f1_score(y_test, predict_lda)\n",
    "    # ç²¾ç¡®ç‡ğŸ‘‰ä¼šæŠ¥â€œWarningâ€ä¸è¦ç´§\n",
    "    precision_tree = precision_score(y_test, predict_tree)\n",
    "    precision_rf = precision_score(y_test, predict_rf)\n",
    "    precision_svc = precision_score(y_test, predict_svc)\n",
    "    precision_mlp = precision_score(y_test, predict_mlp)\n",
    "    precision_knn = precision_score(y_test, predict_knn)\n",
    "    precision_lda = precision_score(y_test, predict_lda)\n",
    "    # å¬å›ç‡\n",
    "    recall_tree = recall_score(y_test, predict_tree)\n",
    "    recall_rf = recall_score(y_test, predict_rf)\n",
    "    recall_svc = recall_score(y_test, predict_svc)\n",
    "    recall_mlp = recall_score(y_test, predict_mlp)\n",
    "    recall_knn = recall_score(y_test, predict_knn)\n",
    "    recall_lda = recall_score(y_test, predict_lda)\n",
    "    \n",
    "    # è®¡ç®—ROCæ›²çº¿çš„AUCå€¼\n",
    "    roc_auc_tree = roc_auc_score(y_test, predict_tree)\n",
    "    roc_auc_rf = roc_auc_score(y_test, predict_rf)\n",
    "    roc_auc_svc = roc_auc_score(y_test, predict_svc)\n",
    "    roc_auc_mlp = roc_auc_score(y_test, predict_mlp)\n",
    "    roc_auc_knn = roc_auc_score(y_test, predict_knn)\n",
    "    roc_auc_lda = roc_auc_score(y_test, predict_lda)\n",
    "\n",
    "    \n",
    "    # å°†ç»“æœå­˜å…¥â€œåˆ—è¡¨â€\n",
    "    re_list.append((re_tree, re_rf, re_svc, re_mlp, re_knn, re_lda))\n",
    "    accuracy_list.append((accuracy_tree, accuracy_rf, accuracy_svc, accuracy_mlp, accuracy_knn, accuracy_lda))\n",
    "    f1_list.append((f1_tree, f1_rf, f1_svc, f1_mlp, f1_knn, f1_lda))\n",
    "    precision_list.append((precision_tree, precision_rf, precision_svc, precision_mlp, precision_knn, precision_lda))\n",
    "    recall_list.append((recall_tree, recall_rf, recall_svc, recall_mlp, recall_knn, recall_lda))\n",
    "    roc_auc_list.append((roc_auc_tree, roc_auc_rf, roc_auc_svc, roc_auc_mlp, roc_auc_knn, roc_auc_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ä¸Šä¸€æ­¥å®Œæˆäº†å¤šæ¬¡å¾ªç¯å®éªŒï¼Œä¸‹é¢æŠŠå­˜å‚¨å¥½çš„è¯¯å·®è¾“å‡ºåˆ°Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        å†³ç­–æ ‘  éšæœºæ£®æ—  æ”¯æŒå‘é‡æœº      ç¥ç»ç½‘ç»œ       KNN      çº¿æ€§åˆ¤åˆ«\n",
      "0  0.546090   0.5    0.5  0.590215  0.510586  0.580588\n",
      "1  0.550986   0.5    0.5  0.583497  0.503386  0.587550\n",
      "2  0.552831   0.5    0.5  0.578821  0.503423  0.568552\n"
     ]
    }
   ],
   "source": [
    "# ä¸ºäº†ä¿å­˜éœ€è¦å…ˆè½¬æ¢æ ¼å¼\n",
    "re_xls = pd.DataFrame(re_list)  # ç›¸å¯¹è¯¯å·®\n",
    "accuracy_xls = pd.DataFrame(accuracy_list)  # å‡†ç¡®ç‡\n",
    "f1_xls = pd.DataFrame(f1_list)  # F1\n",
    "precision_xls = pd.DataFrame(precision_list)  # ç²¾ç¡®ç‡\n",
    "recall_xls = pd.DataFrame(recall_list)  # å¬å›ç‡\n",
    "roc_auc_xls = pd.DataFrame(roc_auc_list)  # ROCæ›²çº¿çš„AUC\n",
    "\n",
    "\n",
    "# ä¿®æ”¹åˆ—åï¼Œç¬¦åˆè¾“å‡ºçš„è¯¯å·®å®šä¹‰\n",
    "new_columns = ['å†³ç­–æ ‘', \"éšæœºæ£®æ—\", \"æ”¯æŒå‘é‡æœº\", \"ç¥ç»ç½‘ç»œ\", \"KNN\", \"çº¿æ€§åˆ¤åˆ«\"] \n",
    "re_xls.columns = new_columns\n",
    "accuracy_xls.columns = new_columns \n",
    "f1_xls.columns = new_columns\n",
    "precision_xls.columns = new_columns\n",
    "recall_xls.columns = new_columns \n",
    "roc_auc_xls.columns = new_columns\n",
    "\n",
    "# è¾“å‡ºå‰ä¸‰è¡Œï¼Œçœ‹çœ‹è€Œå·²\n",
    "print(roc_auc_xls.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æœ€åä¸€æ­¥:è¾“å‡ºexcelåˆ°æŒ‡å®šä½ç½®ï¼Œè·¯å¾„é€‰æ‹©ä½ éœ€è¦çš„\n",
    "#### æ–‡ä»¶åä¸éœ€è¦æ”¹(æœ€åçš„\"åŒæ–œæ \\\\\"åã®å†…å®¹)ğŸ‘‰å·²ç»æŒ‰ç…§â€œæ¨¡å‹ç»“æœ+è¢«è§£é‡Šå˜é‡â€çš„å½¢å¼è®¾ç½®è‡ªåŠ¨å‘½åäº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¾“å‡ºä½ç½®\n",
    "output_file_path = 'C:\\\\Users\\\\iii\\\\Desktop\\\\æ¨¡å‹é¢„æµ‹ç»“æœ%s.xls' % depend_feature[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå¹¶ä¸åŒæ–¹æ³•ä¸ºä¸€ä¸ªæ–‡ä»¶\n",
    "\n",
    "sheet_name = [\"ç›¸å¯¹è¯¯å·®\", \"å‡†ç¡®ç‡\", \"F1\", \"ç²¾ç¡®ç‡\", \"å¬å›ç‡\", \"ROCçš„AUC\"]\n",
    "sheet_name_count = 0\n",
    "writer = pd.ExcelWriter(output_file_path)\n",
    "for xls_output in [re_xls, accuracy_xls, f1_xls, precision_xls, recall_xls, roc_auc_xls]:\n",
    "    xls_output.to_excel(writer, sheet_name=sheet_name[sheet_name_count])\n",
    "    sheet_name_count += 1\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç»“æŸå»–ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
