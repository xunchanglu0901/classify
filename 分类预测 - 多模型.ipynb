{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import precision_recall_curve  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面这个框不需要改动也不需要了解，是建立了\"进度条\"，为了显示后续\"FOR循环\"的进度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "class ProgressBar():\n",
    "\n",
    "    def __init__(self, max_steps):\n",
    "        self.max_steps = max_steps\n",
    "        self.current_step = 0\n",
    "        self.progress_width = 50\n",
    "\n",
    "    def update(self, step=None):\n",
    "        self.current_step = step\n",
    "\n",
    "        num_pass = int(self.current_step * self.progress_width / self.max_steps) + 1\n",
    "        num_rest = self.progress_width - num_pass \n",
    "        percent = (self.current_step+1) * 100.0 / self.max_steps \n",
    "        progress_bar = '[' + '■' * (num_pass-1) + '▶' + '-' * num_rest + ']'\n",
    "        progress_bar += '%.2f' % percent + '%' \n",
    "        if self.current_step < self.max_steps - 1:\n",
    "            progress_bar += '\\r' \n",
    "        else:\n",
    "            progress_bar += '\\n' \n",
    "        sys.stdout.write(progress_bar) \n",
    "        sys.stdout.flush()\n",
    "        if self.current_step >= self.max_steps:\n",
    "            self.current_step = 0\n",
    "            print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入数据\n",
    "#### 根据自己的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"C:\\\\Users\\\\iii\\\\Desktop\\\\data-y.xls\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  第一行是读取出来\n",
    "#### 第二行是插补“线性插补”缺失值 👉 存在缺失值是无法建模\n",
    "#### 第三行是输出“列名”，即变量名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['性别', '男', '年龄', '年龄段', '政治面貌', '党员', '教育年限', '教育程度', '职业九类', '家庭平均年收入',\n",
      "       '地区', '分区', '文化', '制度', '强监督媒体使用', '弱监督媒体使用', '强监督媒体信任', '弱监督媒体信任',\n",
      "       '意识形态', '左', '右', 'Y1', 'Y2', 'Y3', 'Y4', 'Ya', 'Yb', 'Yc', 'Yd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(input_data)\n",
    "data = data.interpolate(method='linear')\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面是构建新变量：①②乘法构建新变量 JH1和JH2  ③ 加法构建新变量👉二分类的Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"JH1\"] = data['意识形态'] * data['强监督媒体使用']\n",
    "data[\"JH2\"] = data['意识形态'] * data['强监督媒体信任']\n",
    "data['Y'] = data['Y1'] + data['Y2'] + data['Y3'] + data['Y4']\n",
    "# print(data[\"JH2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### independ_feature 👉 解释变量 X和D\n",
    "#### depend_feature 👉 被解释变量 Y\n",
    "#### 你可以根据自己的需要👉在里面添加、更换、删除变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "independ_feature = [ '男',  '年龄段', '政治面貌',  '教育程度', '职业九类', '家庭平均年收入',\n",
    "       '地区', '分区', '文化', '制度', '强监督媒体使用',  '强监督媒体信任', '意识形态', 'JH1','JH2']\n",
    "\n",
    "depend_feature = ['Yd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上面的步骤选定了所用变量，下面两行是把data根据解释变量、被解释变量分成两个部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[independ_feature]\n",
    "y = data[depend_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 各个模型，请仔细看注释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 决策回归\n",
    "# clf0 = DecisionTreeRegressor(criterion='mse',max_depth=4)\n",
    "\n",
    "# 决策分类 👉 ①entropy是信息熵;可以换成gini②叶子节点最少的样本数=350,试值后发现这个大小精度好\n",
    "clf_tree = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=350)\n",
    "\n",
    "\n",
    "# 随机森林分类👉①同上②同上③相当于一个随机森林有\"300\"个树\n",
    "clf_rf = RandomForestClassifier(criterion='entropy', min_samples_leaf=350, n_estimators=300)\n",
    "\n",
    "\n",
    "# 支持向量机分类👉①核函数：linear 线性; rbf 径向基核函数\n",
    "clf_svc = svm.SVC(kernel='linear')\n",
    "\n",
    "\n",
    "# 神经网络👉基于多层感知机①solver有lbfgs,sgd,adam用来优化权重,论文可直接使用英文名字,无需详细论述 \n",
    "#                          ②alpha是正则化参数(防止过拟合),1e-5即0.00001\n",
    "#                          ③hidden_   =(10,15,5)的意思是,有“3”个隐藏层，每层神经元“10，15，5”个👉看着调吧,我论文也瞎试的...\n",
    "#                          ④max_iter 迭代计算次数，一般几百就够了，太多了也不一定高。\n",
    "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(10,15, 5),random_state=1, max_iter=300)\n",
    "\n",
    "\n",
    "# KNN👉①n+neighbors每“450”个算一个“邻近”范围，可调，我试了试，450左右还算可以，后期时间充裕再调\n",
    "#       ②weights='distance'即 数据差距越大，越遥远。\n",
    "#       ③leaf_size=30 防止过拟合，默认30 可加大\n",
    "#       ④ p=2, metric='minkowski'即闵可夫斯基距离，常用，不建议改\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=450, weights='distance',\n",
    "                           leaf_size=66, p=2, metric='minkowski')\n",
    "                          \n",
    "# 线性判别\n",
    "# solver:👉svd：奇异值分解求解，无需计算协方差矩阵，适用于特征数量大情形；【其他】lsqr：最小平方QR分解；eigen：特征值分解；\n",
    "clf_lda = LinearDiscriminantAnalysis(solver='svd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为了方便多次试验：\n",
    "#### 建立for循环：每次循环随即切割训练集和测试集；对每个模型进行回归，计算每一次误差并输出excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■▶]100.00%\n"
     ]
    }
   ],
   "source": [
    "# 这里建立误差列表👉方便后面输出到excel\n",
    "re_list = list()\n",
    "accuracy_list = list()\n",
    "f1_list = list()\n",
    "precision_list = list()\n",
    "recall_list = list()\n",
    "roc_auc_list = list()\n",
    "\n",
    "# 循环多次试验\n",
    "test_count = 100  # 👈 修改数字得到多次实验结果\n",
    "progress_bar = ProgressBar(test_count)  # 进度条👉展示循环【总】进度，不需要了解\n",
    "\n",
    "\n",
    "for test_num in range(0,test_count):\n",
    "    progress_bar.update(test_num)  # 进度条【总】进度，不需要了解 \n",
    "    \n",
    "    # 划分👉0.2是测试集占比，可调\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)  # 👈 占比0.2 可调\n",
    "    # 调整格式，便于计算，由原先的数据框→数列\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "    #各个模型：进行拟合\n",
    "    clf_tree.fit(x_train,y_train)\n",
    "    clf_rf.fit(x_train,y_train)\n",
    "    clf_svc.fit(x_train,y_train)\n",
    "    clf_mlp.fit(x_train,y_train)\n",
    "    clf_knn.fit(x_train,y_train) \n",
    "    clf_lda.fit(x_train,y_train)\n",
    "    \n",
    "    #各个模型：预测集の预测结果\n",
    "    predict_tree = clf_tree.predict(x_test)  #各个模型：预测结果\n",
    "    predict_rf = clf_rf.predict(x_test)  #各个模型：预测结果        \n",
    "    predict_svc = clf_svc.predict(x_test)  #各个模型：预测结果\n",
    "    predict_mlp = clf_mlp.predict(x_test)  #各个模型：预测结果\n",
    "    predict_knn = clf_knn.predict(x_test)  #各个模型：预测结果\n",
    "    predict_lda = clf_lda.predict(x_test)  #各个模型：预测结果\n",
    "    \n",
    "    # 误差の RE 相对误差👉①（）是预测和真实的差②差不是0的总数③除以测试集样本量→RE\n",
    "    re_tree = ((predict_tree - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test)\n",
    "    re_rf = ((predict_rf - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test)\n",
    "    re_svc = ((predict_svc - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test) \n",
    "    re_mlp = ((predict_mlp - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test)  \n",
    "    re_knn = ((predict_knn - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test)  \n",
    "    re_lda = ((predict_lda - np.array(y_test).ravel()) != 0).astype(int).sum()/len(y_test)  \n",
    "    \"\"\"\n",
    "    print(\"决策树误差:%.3f\" % re_tree, \"随机森林误差:%.3f\" % re_rf, \"支持向量机误差:%.3f\" % re_svc,\n",
    "          \"神经网络误差:%.3f\" % re_mlp, \"KNN误差:%.3f\" % re_knn, \"线性判别误差:%.3f\" % re_lda, sep=\"\\n\")\n",
    "    \"\"\"\n",
    "    # 准确度 accuracy_score \n",
    "    accuracy_tree = accuracy_score(y_test, predict_tree)\n",
    "    accuracy_rf = accuracy_score(y_test, predict_rf)\n",
    "    accuracy_svc = accuracy_score(y_test, predict_svc)\n",
    "    accuracy_mlp = accuracy_score(y_test, predict_mlp)\n",
    "    accuracy_knn = accuracy_score(y_test, predict_knn)\n",
    "    accuracy_lda = accuracy_score(y_test, predict_lda)\n",
    "    # f1_score\n",
    "    f1_tree = f1_score(y_test, predict_tree)\n",
    "    f1_rf = f1_score(y_test, predict_rf)\n",
    "    f1_svc = f1_score(y_test, predict_svc)\n",
    "    f1_mlp = f1_score(y_test, predict_mlp)\n",
    "    f1_knn = f1_score(y_test, predict_knn)\n",
    "    f1_lda = f1_score(y_test, predict_lda)\n",
    "    # 精确率👉会报“Warning”不要紧\n",
    "    precision_tree = precision_score(y_test, predict_tree)\n",
    "    precision_rf = precision_score(y_test, predict_rf)\n",
    "    precision_svc = precision_score(y_test, predict_svc)\n",
    "    precision_mlp = precision_score(y_test, predict_mlp)\n",
    "    precision_knn = precision_score(y_test, predict_knn)\n",
    "    precision_lda = precision_score(y_test, predict_lda)\n",
    "    # 召回率\n",
    "    recall_tree = recall_score(y_test, predict_tree)\n",
    "    recall_rf = recall_score(y_test, predict_rf)\n",
    "    recall_svc = recall_score(y_test, predict_svc)\n",
    "    recall_mlp = recall_score(y_test, predict_mlp)\n",
    "    recall_knn = recall_score(y_test, predict_knn)\n",
    "    recall_lda = recall_score(y_test, predict_lda)\n",
    "    \n",
    "    # 计算ROC曲线的AUC值\n",
    "    roc_auc_tree = roc_auc_score(y_test, predict_tree)\n",
    "    roc_auc_rf = roc_auc_score(y_test, predict_rf)\n",
    "    roc_auc_svc = roc_auc_score(y_test, predict_svc)\n",
    "    roc_auc_mlp = roc_auc_score(y_test, predict_mlp)\n",
    "    roc_auc_knn = roc_auc_score(y_test, predict_knn)\n",
    "    roc_auc_lda = roc_auc_score(y_test, predict_lda)\n",
    "\n",
    "    \n",
    "    # 将结果存入“列表”\n",
    "    re_list.append((re_tree, re_rf, re_svc, re_mlp, re_knn, re_lda))\n",
    "    accuracy_list.append((accuracy_tree, accuracy_rf, accuracy_svc, accuracy_mlp, accuracy_knn, accuracy_lda))\n",
    "    f1_list.append((f1_tree, f1_rf, f1_svc, f1_mlp, f1_knn, f1_lda))\n",
    "    precision_list.append((precision_tree, precision_rf, precision_svc, precision_mlp, precision_knn, precision_lda))\n",
    "    recall_list.append((recall_tree, recall_rf, recall_svc, recall_mlp, recall_knn, recall_lda))\n",
    "    roc_auc_list.append((roc_auc_tree, roc_auc_rf, roc_auc_svc, roc_auc_mlp, roc_auc_knn, roc_auc_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上一步完成了多次循环实验，下面把存储好的误差输出到Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        决策树  随机森林  支持向量机      神经网络       KNN      线性判别\n",
      "0  0.546090   0.5    0.5  0.590215  0.510586  0.580588\n",
      "1  0.550986   0.5    0.5  0.583497  0.503386  0.587550\n",
      "2  0.552831   0.5    0.5  0.578821  0.503423  0.568552\n"
     ]
    }
   ],
   "source": [
    "# 为了保存需要先转换格式\n",
    "re_xls = pd.DataFrame(re_list)  # 相对误差\n",
    "accuracy_xls = pd.DataFrame(accuracy_list)  # 准确率\n",
    "f1_xls = pd.DataFrame(f1_list)  # F1\n",
    "precision_xls = pd.DataFrame(precision_list)  # 精确率\n",
    "recall_xls = pd.DataFrame(recall_list)  # 召回率\n",
    "roc_auc_xls = pd.DataFrame(roc_auc_list)  # ROC曲线的AUC\n",
    "\n",
    "\n",
    "# 修改列名，符合输出的误差定义\n",
    "new_columns = ['决策树', \"随机森林\", \"支持向量机\", \"神经网络\", \"KNN\", \"线性判别\"] \n",
    "re_xls.columns = new_columns\n",
    "accuracy_xls.columns = new_columns \n",
    "f1_xls.columns = new_columns\n",
    "precision_xls.columns = new_columns\n",
    "recall_xls.columns = new_columns \n",
    "roc_auc_xls.columns = new_columns\n",
    "\n",
    "# 输出前三行，看看而已\n",
    "print(roc_auc_xls.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最后一步:输出excel到指定位置，路径选择你需要的\n",
    "#### 文件名不需要改(最后的\"双斜杠\\\\\"后の内容)👉已经按照“模型结果+被解释变量”的形式设置自动命名了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出位置\n",
    "output_file_path = 'C:\\\\Users\\\\iii\\\\Desktop\\\\模型预测结果%s.xls' % depend_feature[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并不同方法为一个文件\n",
    "\n",
    "sheet_name = [\"相对误差\", \"准确率\", \"F1\", \"精确率\", \"召回率\", \"ROC的AUC\"]\n",
    "sheet_name_count = 0\n",
    "writer = pd.ExcelWriter(output_file_path)\n",
    "for xls_output in [re_xls, accuracy_xls, f1_xls, precision_xls, recall_xls, roc_auc_xls]:\n",
    "    xls_output.to_excel(writer, sheet_name=sheet_name[sheet_name_count])\n",
    "    sheet_name_count += 1\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结束廖！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
